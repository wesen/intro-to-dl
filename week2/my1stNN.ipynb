{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUP8PRZ8Vlgh2BcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269bf2a7a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Relaunch tensorboard, and import useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching processes belonging to you were found\r\n"
     ]
    }
   ],
   "source": [
    "! killall tensorboard\n",
    "import os\n",
    "os.system(\"tensorboard --logdir=/tmp/tboard --port=7007 &\");\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data inspection and preparation\n",
    "\n",
    "We first take a look at the data, and prepare a version having just two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a flattened version of the data, because tensorflow has difficulty computing gradients across a reshape node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"1nn-reshaper\"):\n",
    "    # input shape\n",
    "    x = tf.placeholder(tf.float32, shape=(None, rows, cols), name=\"input_X\")\n",
    "    y = tf.placeholder(tf.uint8, shape=(None,), name=\"input_Y\")\n",
    "\n",
    "    one_hot_y = tf.one_hot(y, 10)\n",
    "    flat_x = tf.reshape(x, [-1, rows * cols])\n",
    "\n",
    "X_train_flat, y_train_one_hot = s.run([flat_x, one_hot_y], feed_dict={\n",
    "    x: X_train,\n",
    "    y: y_train\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer neural network\n",
    "\n",
    "We first create a simple single layer neural network. We use a one_hot encode layer and a reshape layer to create a flat X. This will prove to be troublesome in the future, but it works for the first version. We use a softmax function to compute the predicted classes.\n",
    "\n",
    "Also, for debugging, we create the `correct_prediction` and `accuracy` nodes, to avoid having to compute these metrics by hand after running the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = 28\n",
    "cols = 28\n",
    "classes = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "with tf.variable_scope(\"1nn\"):\n",
    "    weights = tf.get_variable(\"weights\", \n",
    "                              [rows * cols, classes],\n",
    "                              initializer=tf.random_normal_initializer(mean=0, stddev=1e-3),\n",
    "                              dtype=tf.float32)\n",
    "    b = tf.get_variable(\"bias\", [classes],\n",
    "                    initializer=tf.random_uniform_initializer(minval=0, maxval=1e-3),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "    input_X = tf.placeholder(tf.float32, shape=(None, rows, cols), name=\"input_X\")\n",
    "    input_y = tf.placeholder(tf.uint8, shape=(None,), name=\"input_Y\")\n",
    "\n",
    "    one_hot_y = tf.one_hot(input_y, classes)\n",
    "    flat_X = tf.reshape(input_X, [-1, rows * cols])\n",
    "    \n",
    "    predicted_y = tf.nn.softmax(tf.matmul(flat_X, weights) + b)\n",
    "    class_loss = -tf.log(predicted_y) * one_hot_y - tf.log(1 - predicted_y) * (1 - one_hot_y)\n",
    "    loss = tf.reduce_mean(class_loss)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.cast(input_y, tf.int64), tf.argmax(predicted_y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test that the weights get correctly initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  5.79033105e-04,   5.30614925e-04,   3.36251920e-04, ...,\n",
      "          2.76694028e-03,   1.15641451e-03,  -1.63831748e-03],\n",
      "       [ -1.58736168e-03,   1.21381214e-04,  -2.19016010e-03, ...,\n",
      "          1.32015243e-03,   4.94840438e-04,   1.25256577e-03],\n",
      "       [ -3.99170749e-05,   3.11565556e-04,   6.22138497e-04, ...,\n",
      "         -6.53253344e-04,   4.62306161e-05,  -8.24748189e-04],\n",
      "       ..., \n",
      "       [  1.43660349e-04,  -8.87794231e-05,   2.98190513e-04, ...,\n",
      "          2.59238703e-04,   4.58338851e-04,  -1.08343644e-04],\n",
      "       [  8.14772618e-04,   6.56542543e-04,   1.24888425e-03, ...,\n",
      "         -9.27994843e-04,  -7.12979992e-04,   1.58063893e-03],\n",
      "       [  5.21749025e-04,  -1.53792300e-03,   1.33906677e-03, ...,\n",
      "         -1.45935116e-03,  -2.51419330e-03,   1.67449866e-03]], dtype=float32), array([  2.86260271e-04,   9.36999510e-04,   8.29001729e-05,\n",
      "         5.16016968e-04,   8.68820585e-04,   6.75416377e-04,\n",
      "         8.76370585e-04,   2.40242618e-04,   2.61650217e-04,\n",
      "         6.24309832e-05], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "print(s.run([weights, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test that the network computes different values correctly, or at least that they seem to be roughly correct. I struggled a bit with different data shapes and wrong initialization. I decided to keep this step to show what pains I went through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  5.79033105e-04,   5.30614925e-04,   3.36251920e-04, ...,\n",
       "           2.76694028e-03,   1.15641451e-03,  -1.63831748e-03],\n",
       "        [ -1.58736168e-03,   1.21381214e-04,  -2.19016010e-03, ...,\n",
       "           1.32015243e-03,   4.94840438e-04,   1.25256577e-03],\n",
       "        [ -3.99170749e-05,   3.11565556e-04,   6.22138497e-04, ...,\n",
       "          -6.53253344e-04,   4.62306161e-05,  -8.24748189e-04],\n",
       "        ..., \n",
       "        [  1.43660349e-04,  -8.87794231e-05,   2.98190513e-04, ...,\n",
       "           2.59238703e-04,   4.58338851e-04,  -1.08343644e-04],\n",
       "        [  8.14772618e-04,   6.56542543e-04,   1.24888425e-03, ...,\n",
       "          -9.27994843e-04,  -7.12979992e-04,   1.58063893e-03],\n",
       "        [  5.21749025e-04,  -1.53792300e-03,   1.33906677e-03, ...,\n",
       "          -1.45935116e-03,  -2.51419330e-03,   1.67449866e-03]], dtype=float32),\n",
       " array([  2.86260271e-04,   9.36999510e-04,   8.29001729e-05,\n",
       "          5.16016968e-04,   8.68820585e-04,   6.75416377e-04,\n",
       "          8.76370585e-04,   2.40242618e-04,   2.61650217e-04,\n",
       "          6.24309832e-05], dtype=float32),\n",
       " array([[ 0.10137516,  0.10030492,  0.09839335,  0.10016569,  0.10039964,\n",
       "          0.10035313,  0.09931353,  0.09967161,  0.09963091,  0.10039211],\n",
       "        [ 0.10024301,  0.10021225,  0.10119337,  0.09891429,  0.10105252,\n",
       "          0.09899658,  0.10070042,  0.09855074,  0.10112355,  0.0990133 ],\n",
       "        [ 0.09860776,  0.0992314 ,  0.09991227,  0.1002026 ,  0.10112312,\n",
       "          0.10064189,  0.09889916,  0.09989031,  0.10192948,  0.099562  ]], dtype=float32),\n",
       " array([[ 0.10688964,  0.10569935,  0.10357691,  0.10554467,  0.10580463,\n",
       "          2.29906011,  0.10459802,  0.1049957 ,  0.10495048,  0.10579628],\n",
       "        [ 2.30015802,  0.10559641,  0.10668736,  0.10415487,  0.10653067,\n",
       "          0.10424622,  0.10613909,  0.10375152,  0.10660971,  0.10426481],\n",
       "        [ 0.1038148 ,  0.10450691,  0.10526306,  0.10558567,  2.29141641,\n",
       "          0.106074  ,  0.10413814,  0.10523862,  0.10750669,  0.10487396]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32),\n",
       " 0.32444909,\n",
       " array([False, False, False], dtype=bool),\n",
       " 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.run([weights, b, predicted_y, class_loss, one_hot_y, loss, correct_prediction, accuracy],\n",
    "     {\n",
    "         input_X: X_train[:3],\n",
    "         input_y: y_train[:3]\n",
    "     })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute accuracy metrics when training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "losses = []\n",
    "test_accuracies = []\n",
    "train_accuracies = []\n",
    "\n",
    "for i in range(30):\n",
    "    s.run(optimizer, {input_X: X_train, input_y: y_train})\n",
    "    loss_i = s.run(loss,  {input_X: X_train, input_y: y_train})\n",
    "    losses += [loss_i]\n",
    "    train_accuracies += [s.run(accuracy, {input_X:X_train, input_y: y_train})]\n",
    "    test_accuracies += [s.run(accuracy, {input_X:X_test, input_y: y_test})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11019aeb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw10ppRLQ/w/MzGip5KSjnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c27d780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses);\n",
    "plt.plot(train_accuracies)\n",
    "plt.plot(test_accuracies);\n",
    "plt.legend(['loss', 'training accuracy', 'test accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer neural network\n",
    "\n",
    "In this neural network, we use a second 50 neuron layer. The first layer has a sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m50\u001b[0m\n\u001b[1;33m    initializer=tf.zeros_initializer(),\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "rows = 28\n",
    "cols = 28\n",
    "classes = 10\n",
    "\n",
    "layer_cnt = 0\n",
    "\n",
    "def add_layer(in_, size):\n",
    "    W2 = tf.get_variable(\"weights{}\".format(layer_cnt), \n",
    "                              [in_.shape[1], size],\n",
    "                              initializer=tf.random_normal_initializer(mean=0, stddev=sigma),\n",
    "                              dtype=tf.float32)\n",
    "    b2 = tf.get_variable(\"bias{}\".format(layer_cnt), [in_.shape[1]],\n",
    "                    initializer=tf.zeros_initializer(),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "    y2 = tf.nn.softmax(tf.matmulin_, W2) + b2)\n",
    "    \n",
    "    layer_cnt += 1\n",
    "    return y2\n",
    "\n",
    "hidden_size = 30\n",
    "\n",
    "tf.reset_default_graph()\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "with tf.variable_scope(\"1nn-2layers\"):\n",
    "    # input shape\n",
    "    input_x = tf.placeholder(tf.float32, shape=(None, rows, cols), name=\"input_X\")\n",
    "    label_y = tf.placeholder(tf.uint8, shape=(None,), name=\"input_Y\")\n",
    "\n",
    "    y_ = tf.one_hot(label_y, classes, dtype=tf.float32)\n",
    "    x = tf.reshape(input_x, [-1, rows * cols])\n",
    "    \n",
    "    sigma = np.sqrt(2. / 10.)\n",
    "    sigma = 0.4\n",
    "    print(\"sigma\", sigma)\n",
    "  \n",
    "    # input layer\n",
    "    W1 = tf.get_variable(\"weights\", \n",
    "                              [rows * cols, hidden_size],\n",
    "                              initializer=tf.random_normal_initializer(mean=0, stddev=sigma),\n",
    "                              dtype=tf.float32)\n",
    "    b1 = tf.get_variable(\"bias\", [hidden_size],\n",
    "                    initializer=tf.zeros_initializer(),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "    y1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)\n",
    "\n",
    "    # hidden layer\n",
    "    W2 = tf.get_variable(\"hidden_weights\", \n",
    "                              [hidden_size, hidden_size],\n",
    "                              initializer=tf.random_normal_initializer(mean=0, stddev=sigma),\n",
    "                              dtype=tf.float32)\n",
    "    b2 = tf.get_variable(\"hidden_bias\", [hidden_size],\n",
    "                    initializer=tf.zeros_initializer(),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "    y2 = tf.nn.softmax(tf.matmul(y1, W2) + b2)\n",
    "\n",
    "    # hidden layer\n",
    "    W3 = tf.get_variable(\"hidden_weights2\", \n",
    "                              [hidden_size, classes],\n",
    "                              initializer=tf.random_normal_initializer(mean=0, stddev=sigma),\n",
    "                              dtype=tf.float32)\n",
    "    b3 = tf.get_variable(\"hidden_bias2\", [classes],\n",
    "                    initializer=tf.zeros_initializer(),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "    y3 = tf.nn.softmax(tf.matmul(y2, W3) + b3)\n",
    "\n",
    "    # output\n",
    "    y = y3\n",
    "\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(tf.cast(y_, tf.float32) * tf.log(y), \n",
    "    reduction_indices=[1]))\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(2.).minimize(loss)\n",
    "    \n",
    "    s.run(tf.global_variables_initializer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a generator that will provide us with randomized minibatches, to do incremental training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MiniBatchGenerator:\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.X = X.copy()\n",
    "        self.y = y.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.current_i = 0\n",
    "        self.total_size = len(self.X)\n",
    "        \n",
    "        self.reshuffle()\n",
    "        \n",
    "    def reshuffle(self):        \n",
    "        idxs = list(range(self.total_size))\n",
    "        random.shuffle(idxs)\n",
    "        self.X_shuffled = self.X[idxs]\n",
    "        self.y_shuffled = self.y[idxs]        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        res_X = []\n",
    "        res_y = []\n",
    "        \n",
    "        end_i = self.current_i + self.batch_size\n",
    "        \n",
    "        if end_i > self.total_size:\n",
    "            rem = end_i - self.total_size\n",
    "            res_X = self.X_shuffled[self.current_i:]\n",
    "            res_y = self.y_shuffled[self.current_i:]\n",
    "            self.reshuffle()\n",
    "            res_X = np.append(res_X, self.X_shuffled[:rem], axis=0)\n",
    "            res_y = np.append(res_y, self.y_shuffled[:rem])\n",
    "            self.current_i = rem\n",
    "        else:\n",
    "            res_X = self.X_shuffled[self.current_i:end_i]\n",
    "            res_y = self.y_shuffled[self.current_i:end_i]\n",
    "            self.current_i = end_i\n",
    "        \n",
    "        return res_X, res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(50000,)\n",
      "loss at iter 0:2.3284\n",
      "train accuracy: 0.063\n",
      "loss at iter 100:1.3399\n",
      "train accuracy: 0.421\n",
      "loss at iter 200:1.1936\n",
      "train accuracy: 0.502\n",
      "loss at iter 300:0.9971\n",
      "train accuracy: 0.583\n",
      "loss at iter 400:0.9223\n",
      "train accuracy: 0.618\n",
      "loss at iter 500:0.8193\n",
      "train accuracy: 0.682\n",
      "loss at iter 600:0.7426\n",
      "train accuracy: 0.729\n",
      "loss at iter 700:0.9437\n",
      "train accuracy: 0.594\n",
      "loss at iter 800:0.7265\n",
      "train accuracy: 0.701\n",
      "loss at iter 900:0.6475\n",
      "train accuracy: 0.8\n",
      "loss at iter 1000:0.6578\n",
      "train accuracy: 0.815\n",
      "loss at iter 1100:0.6384\n",
      "train accuracy: 0.834\n",
      "loss at iter 1200:0.4520\n",
      "train accuracy: 0.894\n",
      "loss at iter 1300:0.4416\n",
      "train accuracy: 0.883\n",
      "loss at iter 1400:0.3321\n",
      "train accuracy: 0.928\n",
      "loss at iter 1500:0.3690\n",
      "train accuracy: 0.916\n",
      "loss at iter 1600:0.3002\n",
      "train accuracy: 0.927\n",
      "loss at iter 1700:0.2532\n",
      "train accuracy: 0.933\n",
      "loss at iter 1800:0.6706\n",
      "train accuracy: 0.761\n",
      "loss at iter 1900:0.2402\n",
      "train accuracy: 0.94\n",
      "loss at iter 2000:0.2027\n",
      "train accuracy: 0.947\n",
      "loss at iter 2100:0.2004\n",
      "train accuracy: 0.96\n",
      "loss at iter 2200:0.1874\n",
      "train accuracy: 0.957\n",
      "loss at iter 2300:0.2102\n",
      "train accuracy: 0.947\n",
      "loss at iter 2400:0.1763\n",
      "train accuracy: 0.952\n",
      "loss at iter 2500:0.2073\n",
      "train accuracy: 0.958\n",
      "loss at iter 2600:0.2184\n",
      "train accuracy: 0.937\n",
      "loss at iter 2700:0.1564\n",
      "train accuracy: 0.961\n",
      "loss at iter 2800:0.1950\n",
      "train accuracy: 0.958\n",
      "loss at iter 2900:0.1400\n",
      "train accuracy: 0.971\n",
      "loss at iter 3000:0.1709\n",
      "train accuracy: 0.95\n",
      "loss at iter 3100:0.1474\n",
      "train accuracy: 0.964\n",
      "loss at iter 3200:0.1884\n",
      "train accuracy: 0.951\n",
      "loss at iter 3300:0.1600\n",
      "train accuracy: 0.962\n",
      "loss at iter 3400:0.1332\n",
      "train accuracy: 0.967\n",
      "loss at iter 3500:0.1233\n",
      "train accuracy: 0.97\n",
      "loss at iter 3600:0.1202\n",
      "train accuracy: 0.975\n",
      "loss at iter 3700:0.1544\n",
      "train accuracy: 0.963\n",
      "Total accuracy: 0.9683197736740112\n",
      "loss at iter 3800:0.1175\n",
      "train accuracy: 0.972\n",
      "loss at iter 3900:0.1054\n",
      "train accuracy: 0.975\n",
      "Total accuracy: 0.969559907913208\n",
      "loss at iter 4000:0.1285\n",
      "train accuracy: 0.968\n",
      "Total accuracy: 0.970619797706604\n",
      "Total accuracy: 0.9703198075294495\n",
      "Total accuracy: 0.9720598459243774\n",
      "Total accuracy: 0.9694197773933411\n",
      "Total accuracy: 0.9705197811126709\n",
      "loss at iter 4100:0.1170\n",
      "train accuracy: 0.974\n",
      "loss at iter 4200:0.1652\n",
      "train accuracy: 0.96\n",
      "Total accuracy: 0.9710997939109802\n",
      "Total accuracy: 0.971319854259491\n",
      "Total accuracy: 0.9717597961425781\n",
      "Total accuracy: 0.9721998572349548\n",
      "Total accuracy: 0.9724797606468201\n",
      "loss at iter 4300:0.1058\n",
      "train accuracy: 0.973\n",
      "Total accuracy: 0.9724597334861755\n",
      "Total accuracy: 0.9728997945785522\n",
      "Total accuracy: 0.9697397947311401\n",
      "Total accuracy: 0.9707998633384705\n",
      "Total accuracy: 0.9721599221229553\n",
      "loss at iter 4400:0.1018\n",
      "train accuracy: 0.977\n",
      "Total accuracy: 0.9727797508239746\n",
      "Total accuracy: 0.9725397229194641\n",
      "Total accuracy: 0.9727398157119751\n",
      "Total accuracy: 0.9733197689056396\n",
      "Total accuracy: 0.9737597107887268\n",
      "loss at iter 4500:0.1667\n",
      "train accuracy: 0.965\n",
      "Total accuracy: 0.9728597402572632\n",
      "Total accuracy: 0.9739397764205933\n",
      "Total accuracy: 0.9739598035812378\n",
      "Total accuracy: 0.9740197658538818\n",
      "Total accuracy: 0.9736797213554382\n",
      "Total accuracy: 0.9713597297668457\n",
      "Total accuracy: 0.9736397862434387\n",
      "Total accuracy: 0.9737198352813721\n",
      "Total accuracy: 0.9726598858833313\n",
      "loss at iter 4600:0.1263\n",
      "train accuracy: 0.977\n",
      "Total accuracy: 0.9741997718811035\n",
      "Total accuracy: 0.9738798141479492\n",
      "Total accuracy: 0.9739198684692383\n",
      "Total accuracy: 0.9741198420524597\n",
      "loss at iter 4700:0.1556\n",
      "train accuracy: 0.967\n",
      "Total accuracy: 0.9746997356414795\n",
      "Total accuracy: 0.974639892578125\n",
      "Total accuracy: 0.9741398692131042\n",
      "Total accuracy: 0.974199652671814\n",
      "Total accuracy: 0.9745398759841919\n",
      "Total accuracy: 0.9751397371292114\n",
      "Total accuracy: 0.9739197492599487\n",
      "Total accuracy: 0.9748398065567017\n",
      "loss at iter 4800:0.1460\n",
      "train accuracy: 0.964\n",
      "Total accuracy: 0.9737597703933716\n",
      "Total accuracy: 0.9737797379493713\n",
      "Total accuracy: 0.9744597673416138\n",
      "Total accuracy: 0.9736597537994385\n",
      "Total accuracy: 0.9755197763442993\n",
      "Total accuracy: 0.9742398262023926\n",
      "Total accuracy: 0.9741596579551697\n",
      "Total accuracy: 0.9756797552108765\n",
      "Total accuracy: 0.9746397733688354\n",
      "Total accuracy: 0.9749798774719238\n",
      "Total accuracy: 0.9753598570823669\n",
      "Total accuracy: 0.9756998419761658\n",
      "Total accuracy: 0.9758798480033875\n",
      "loss at iter 4900:0.2229\n",
      "train accuracy: 0.944\n",
      "Total accuracy: 0.9734199047088623\n",
      "Total accuracy: 0.9735397696495056\n",
      "Total accuracy: 0.9746797680854797\n",
      "Total accuracy: 0.9761397242546082\n",
      "Total accuracy: 0.9756197929382324\n",
      "Total accuracy: 0.9755998253822327\n",
      "Total accuracy: 0.9757997393608093\n",
      "Total accuracy: 0.9752597808837891\n",
      "Total accuracy: 0.9760197997093201\n",
      "loss at iter 5000:0.1318\n",
      "train accuracy: 0.972\n",
      "Total accuracy: 0.9745197892189026\n",
      "Total accuracy: 0.9766197800636292\n",
      "Total accuracy: 0.9761598110198975\n",
      "Total accuracy: 0.9743998050689697\n",
      "Total accuracy: 0.9757397770881653\n",
      "Total accuracy: 0.975919783115387\n",
      "Total accuracy: 0.9762997627258301\n",
      "Total accuracy: 0.9733997583389282\n",
      "Total accuracy: 0.9766398668289185\n",
      "Total accuracy: 0.9766597747802734\n",
      "Total accuracy: 0.9772998690605164\n",
      "Total accuracy: 0.9760197401046753\n",
      "Total accuracy: 0.9760197401046753\n",
      "loss at iter 5100:0.1000\n",
      "train accuracy: 0.98\n",
      "Total accuracy: 0.9736797213554382\n",
      "Total accuracy: 0.9752798080444336\n",
      "Total accuracy: 0.9759997129440308\n",
      "Total accuracy: 0.9765398502349854\n",
      "Total accuracy: 0.976239800453186\n",
      "Total accuracy: 0.9735598564147949\n",
      "Total accuracy: 0.9765197038650513\n",
      "Total accuracy: 0.9761597514152527\n",
      "Total accuracy: 0.97437983751297\n",
      "Total accuracy: 0.9773998260498047\n",
      "Total accuracy: 0.9768198132514954\n",
      "loss at iter 5200:0.1019\n",
      "train accuracy: 0.975\n",
      "Total accuracy: 0.9756197929382324\n",
      "Total accuracy: 0.9753798246383667\n",
      "Total accuracy: 0.9739397764205933\n",
      "Total accuracy: 0.9773398041725159\n",
      "Total accuracy: 0.977459728717804\n",
      "Total accuracy: 0.9765998125076294\n",
      "Total accuracy: 0.9738596677780151\n",
      "Total accuracy: 0.9775797724723816\n",
      "Total accuracy: 0.9758397340774536\n",
      "Total accuracy: 0.9766598343849182\n",
      "Total accuracy: 0.9769197702407837\n",
      "Total accuracy: 0.9778797030448914\n",
      "Total accuracy: 0.9776198267936707\n",
      "Total accuracy: 0.9777998328208923\n",
      "Total accuracy: 0.9771397709846497\n",
      "loss at iter 5300:0.1051\n",
      "train accuracy: 0.976\n",
      "Total accuracy: 0.9772997498512268\n",
      "Total accuracy: 0.9777398109436035\n",
      "Total accuracy: 0.9775997996330261\n",
      "Total accuracy: 0.9780397415161133\n",
      "Total accuracy: 0.9774997234344482\n",
      "Total accuracy: 0.9774397611618042\n",
      "Total accuracy: 0.9776197671890259\n",
      "Total accuracy: 0.9775198101997375\n",
      "Total accuracy: 0.9774998426437378\n",
      "Total accuracy: 0.977019727230072\n",
      "Total accuracy: 0.973899781703949\n",
      "Total accuracy: 0.9780798554420471\n",
      "Total accuracy: 0.9783998131752014\n",
      "Total accuracy: 0.9770398139953613\n",
      "Total accuracy: 0.977279782295227\n",
      "Total accuracy: 0.9738597869873047\n",
      "Total accuracy: 0.9767996668815613\n",
      "Total accuracy: 0.9769597053527832\n",
      "Total accuracy: 0.976879894733429\n",
      "Total accuracy: 0.9779398441314697\n",
      "Total accuracy: 0.978259801864624\n",
      "Total accuracy: 0.9781597852706909\n",
      "Total accuracy: 0.9781197905540466\n",
      "Total accuracy: 0.9781597852706909\n",
      "loss at iter 5400:0.1987\n",
      "train accuracy: 0.946\n",
      "Total accuracy: 0.9760797619819641\n",
      "Total accuracy: 0.9745797514915466\n",
      "Total accuracy: 0.9772998094558716\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-df04091ab7f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         ,  {input_x: X_train, \n\u001b[1;32m---> 23\u001b[1;33m              label_y: y_train})\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total accuracy: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    952\u001b[0m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \"\"\"\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batcher = MiniBatchGenerator(X_train, y_train, 1000)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "for i in range(10000):\n",
    "    X_batch, y_batch = batcher.next()\n",
    "    \n",
    "    loss_i, accuracy_i, optimizer_i = s.run([\n",
    "        loss, accuracy, optimizer\n",
    "    ],  {input_x: X_batch, \n",
    "                     label_y: y_batch})\n",
    "    if i % 100 == 0:\n",
    "        print(\"loss at iter %i:%.4f\" % (i, loss_i))\n",
    "        print(\"train accuracy:\", accuracy_i)\n",
    "    \n",
    "    \n",
    "    if accuracy_i > 0.98:\n",
    "        accuracy_i = s.run(\n",
    "            accuracy \n",
    "        ,  {input_x: X_train, \n",
    "             label_y: y_train})\n",
    "        print(\"Total accuracy: {}\".format(accuracy_i))\n",
    "\n",
    "accuracy_i = s.run([\n",
    "    accuracy\n",
    "],  {input_x: X_test, \n",
    "     label_y: y_test})\n",
    "\n",
    "print(\"test_accuracy:\", accuracy_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: [0.94780004]\n"
     ]
    }
   ],
   "source": [
    "accuracy_i = s.run([\n",
    "    accuracy\n",
    "],  {input_x: X_test, \n",
    "     label_y: y_test})\n",
    "\n",
    "print(\"test_accuracy:\", accuracy_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "28 * 28 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
