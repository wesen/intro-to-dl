{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y [shape - (360,)]: [0 1 0 1 0 1 0 0 1 1]\n",
      "X [shape - (360, 64)]:\n",
      "[ 0.59420049  0.59367478  0.59943277  0.59905577  0.60508949  0.61222959\n",
      "  0.6101138   0.60510671  0.58051741  0.58661669]\n",
      "[0 1 0 1 0 1 0 0 1 1]\n",
      "0.728689\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib_utils\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits(2)\n",
    "\n",
    "X, y = mnist.data, mnist.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)\n",
    "\n",
    "print(\"y [shape - %s]:\" % (str(y.shape)), y[:10])\n",
    "print(\"X [shape - %s]:\" % (str(X.shape)))\n",
    "\n",
    "with tf.name_scope(\"MSE\"):\n",
    "    y_true = tf.placeholder(\"float32\", shape=(None,), name=\"y_true\")\n",
    "    y_predicted = tf.placeholder(\"float32\", shape=(None,), name=\"y_predicted\")\n",
    "    \n",
    "    mse = tf.reduce_mean((y_predicted - y_true)**2)\n",
    "\n",
    "def compute_mse(vector1, vector2):\n",
    "    return mse.eval({y_true: vector1, y_predicted: vector2})\n",
    "\n",
    "\n",
    "weights = logreg_weights = tf.Variable(initial_value=tf.zeros((X.shape[1],1), dtype=tf.float32), name=\"weights\")\n",
    "b = logreg_bias = tf.Variable(initial_value=0., dtype=\"float32\", name=\"bias\")\n",
    "input_X = logreg_input_x = tf.placeholder(\"float32\", shape=(None,64), name=\"X\")\n",
    "input_y = logreg_input_y = tf.placeholder(\"float32\", shape=(None,), name=\"y\")\n",
    "\n",
    "# print(logreg_input_x.shape)\n",
    "# print(logreg_weights.shape)\n",
    "matmul = tf.matmul(logreg_input_x, logreg_weights)\n",
    "# print(matmul.shape)\n",
    "squeezed = tf.squeeze(matmul)\n",
    "# print(squeezed.shape)\n",
    "# print(logreg_bias.shape)\n",
    "preds = matmul + logreg_bias\n",
    "\n",
    "# logreg_preds = tf.nn.sigmoid(tf.squeeze(tf.matmul(logreg_input_x, logreg_weights)) + logreg_bias)\n",
    "logreg_preds = tf.squeeze(tf.nn.sigmoid(preds))\n",
    "\n",
    "predicted_y = logreg_preds\n",
    "# print(predicted_y.shape)\n",
    "# print((predicted_y * logreg_input_y).shape)\n",
    "\n",
    "# tmp_node = predicted_y * logreg_input_y\n",
    "\n",
    "loss_a = -tf.log(predicted_y) * input_y\n",
    "loss_b = tf.log(1 - predicted_y) * (1 - input_y)\n",
    "loss_sum = loss_a - loss_b\n",
    "loss = tf.reduce_mean(loss_sum)\n",
    "\n",
    "l = -input_y*tf.log(predicted_y) - (1-input_y)*tf.log(1-predicted_y)\n",
    "\n",
    "loss = tf.reduce_mean(l)\n",
    "\n",
    "# loss = tf.reduce_mean(-tf.reduce_sum(input_y*tf.log(predicted_y)))\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=input_y))\n",
    "\n",
    "# print(loss.shape)\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.5) \\\n",
    "    .minimize(loss, var_list=[weights, b])\n",
    "\n",
    "tf.summary.FileWriterCache.clear()\n",
    "writer = tf.summary.FileWriter(\"/tmp/tboard\", graph=loss.graph)\n",
    "writer.flush()\n",
    "\n",
    "my_scalar = tf.placeholder('float32')\n",
    "my_vector = tf.placeholder('float32', [None])\n",
    "# Compute the gradient of the next weird function over my_scalar and my_vector\n",
    "# Warning! Trying to understand the meaning of that function may result in permanent brain damage\n",
    "weird_psychotic_function = tf.reduce_mean(\n",
    "    (my_vector+my_scalar)**(1+tf.nn.moments(my_vector,[0])[1]) + \n",
    "    1./ tf.atan(my_scalar))/(my_scalar**2 + 1) + 0.01*tf.sin(\n",
    "    2*my_scalar**1.5)*(tf.reduce_sum(my_vector)* my_scalar**2\n",
    "                      )*tf.exp((my_scalar-4)**2)/(\n",
    "    1+tf.exp((my_scalar-4)**2))*(1.-(tf.exp(-(my_scalar-4)**2)\n",
    "                                    )/(1+tf.exp(-(my_scalar-4)**2)))**2\n",
    "\n",
    "der_by_scalar = tf.gradients(weird_psychotic_function, my_scalar)\n",
    "der_by_vector = tf.gradients(weird_psychotic_function, my_vector)\n",
    "\n",
    "validation_weights = 1e-3 * np.fromiter(map(lambda x:\n",
    "        s.run(weird_psychotic_function, {my_scalar:x, my_vector:[1, 0.1, 2]}),\n",
    "                                   0.15 * np.arange(1, X.shape[1] + 1)),\n",
    "                                   count=X.shape[1], dtype=np.float32)[:, np.newaxis]\n",
    "# Compute predictions for given weights and bias\n",
    "prediction_validation = s.run(\n",
    "    predicted_y, {\n",
    "    input_X: X,\n",
    "    weights: validation_weights,\n",
    "    b: 1e-1})\n",
    "\n",
    "# Load the reference values for the predictions\n",
    "validation_true_values = np.loadtxt(\"validation_predictons.txt\")\n",
    "\n",
    "assert prediction_validation.shape == (X.shape[0],),\\\n",
    "       \"Predictions must be a 1D array with length equal to the number \" \\\n",
    "       \"of examples in input_X\"\n",
    "assert np.allclose(validation_true_values, prediction_validation)\n",
    "\n",
    "# print(prediction_validation)\n",
    "\n",
    "# Compute predictions for given weights and bias\n",
    "tmp_ = s.run(\n",
    "    predicted_y, {\n",
    "    input_X: X[:100],\n",
    "    input_y: y[:100],\n",
    "    weights: validation_weights + 1.21e-3,\n",
    "    b: -1e-1})\n",
    "\n",
    "print(prediction_validation[:10])\n",
    "print(y[:10])\n",
    "\n",
    "loss_validation = s.run(\n",
    "        loss, {\n",
    "            input_X: X[:100],\n",
    "            input_y: y[-100:],\n",
    "            weights: validation_weights+1.21e-3,\n",
    "            b: -1e-1})\n",
    "print(loss_validation)\n",
    "assert np.allclose(loss_validation, 0.728689)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 0:0.0554\n",
      "train auc: 0.999945103206\n",
      "test auc: 1.0\n",
      "loss at iter 1:0.0257\n",
      "train auc: 1.0\n",
      "test auc: 1.0\n",
      "loss at iter 2:0.0175\n",
      "train auc: 1.0\n",
      "test auc: 1.0\n",
      "loss at iter 3:0.0148\n",
      "train auc: 1.0\n",
      "test auc: 1.0\n",
      "loss at iter 4:0.0133\n",
      "train auc: 1.0\n",
      "test auc: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "s.run(tf.global_variables_initializer())\n",
    "# weights.assign(validation_weights)\n",
    "for i in range(5):\n",
    "#     print(s.run(weights[:10]))\n",
    "#     print(\"preds\", s.run(preds, {input_X: X_train[:10], input_y: y_train[:10]}))\n",
    "#     print(\"predicted_y\", s.run(predicted_y, {input_X: X_train[:10], input_y: y_train[:10]}))\n",
    "#     print(\"loss_a\", s.run(loss_a, {input_X: X_train[:10], input_y: y_train[:10]}))\n",
    "#     print(\"loss_a\", s.run(loss_a, {input_X: X_train, input_y: y_train}))\n",
    "#     print(\"loss_b\", s.run(loss_b, {input_X: X_train[:10], input_y: y_train[:10]}))\n",
    "#     print(\"loss\", s.run(loss, {input_X: X_train[:10], input_y: y_train[:10]}))\n",
    "#     print(\"y_train\", y_train[:10])\n",
    "\n",
    "    tmp =     s.run(optimizer, {input_X: X_train[:10], input_y: y_train[:10]})\n",
    "#     print(s.run(weights[:10]))\n",
    "    \n",
    "    s.run(optimizer, {input_X: X_train, input_y: y_train})\n",
    "#     print(s.run(weights[:10]))\n",
    "    loss_i = s.run(loss, {input_X: X_train, input_y: y_train})\n",
    "    print(\"loss at iter %i:%.4f\" % (i, loss_i))\n",
    "    print(\"train auc:\", roc_auc_score(y_train, s.run(predicted_y, {input_X:X_train})))\n",
    "    print(\"test auc:\", roc_auc_score(y_test, s.run(predicted_y, {input_X:X_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import grading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_weights = 1e-3 * np.fromiter(map(lambda x:\n",
    "    s.run(weird_psychotic_function, {my_scalar:x, my_vector:[1, 2, 3]}),\n",
    "                               0.1 * np.arange(1, X.shape[1] + 1)),\n",
    "                               count=X.shape[1], dtype=np.float32)[:, np.newaxis]\n",
    "\n",
    "prediction_test = s.run(\n",
    "    predicted_y, {\n",
    "    input_X: X,\n",
    "    weights: test_weights,\n",
    "    b: 1e-1})\n",
    "\n",
    "assert prediction_test.shape == (X.shape[0],),\\\n",
    "       \"Predictions must be a 1D array with length equal to the number \" \\\n",
    "       \"of examples in X_test\"\n",
    "        \n",
    "loss_test = s.run(\n",
    "    loss, {\n",
    "        input_X: X[:100],\n",
    "        input_y: y[-100:],\n",
    "        weights: test_weights+1.21e-3,\n",
    "        b: -1e-1})\n",
    "# Yes, the X/y indices mistmach is intentional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission doesn't reference all parts of the assignment. Please make sure you have included references to all parts within your submission. Try downloading the latest starter files if the issue still persists.\n"
     ]
    }
   ],
   "source": [
    "grade_submitter = grading.Grader(\"BJCiiY8sEeeCnhKCj4fcOA\")\n",
    "\n",
    "grade_submitter.set_answer(\"0ENlN\", prediction_test)\n",
    "grade_submitter.set_answer(\"D16Rc\", roc_auc_score(y_test, s.run(predicted_y, {input_X:X_test})))\n",
    "\n",
    "grade_submitter.submit('wesen@ruinwesen.com', '5rTVia02zPBGNfYn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
