{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting deeper with Keras\n",
    "* Tensorflow is a powerful and flexible tool, but coding large neural architectures with it is tedious.\n",
    "* There are plenty of deep learning toolkits that work on top of it like Slim, TFLearn, Sonnet, Keras.\n",
    "* Choice is matter of taste and particular task\n",
    "* We'll be using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use preloaded keras datasets and models\n",
    "! mkdir -p ~/.keras/datasets\n",
    "! mkdir -p ~/.keras/models\n",
    "! ln -s $(realpath ../readonly/keras/datasets/*) ~/.keras/datasets/\n",
    "! ln -s $(realpath ../readonly/keras/models/*) ~/.keras/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from preprocessed_mnist import load_dataset\n",
    "import keras\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "x_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "y_train,y_val,y_test = map(keras.utils.np_utils.to_categorical,[y_train,y_val,y_test])\n",
    "x_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a294320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap='Greys');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pretty keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "import keras.layers as ll\n",
    "import keras.initializers\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential(name=\"mlp\")\n",
    "\n",
    "# model.add(ll.InputLayer([28, 28]))\n",
    "# model.add(ll.Flatten())\n",
    "\n",
    "# # network body\n",
    "# model.add(ll.Dense(\n",
    "#     784, \n",
    "#     kernel_regularizer=regularizers.l2(0.01),\n",
    "#     kernel_initializer='normal'\n",
    "#          ))\n",
    "# model.add(ll.Activation('relu'))\n",
    "\n",
    "# model.add(ll.Dense(25))\n",
    "# model.add(ll.Activation('relu'))\n",
    "\n",
    "model.add(ll.Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(ll.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(ll.Dropout(0.2))\n",
    "model.add(ll.Flatten())\n",
    "model.add(ll.Dense(128, activation='relu'))\n",
    "    \n",
    "\n",
    "# output layer: 10 neurons for each class with softmax\n",
    "model.add(ll.Dense(10, activation='softmax', kernel_initializer='normal'))\n",
    "\n",
    "# categorical_crossentropy is your good old crossentropy\n",
    "# but applied for one-hot-encoded vectors\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 592,074\n",
      "Trainable params: 592,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model interface\n",
    "\n",
    "Keras models follow __Scikit-learn__'s interface of fit/predict with some notable extensions. Let's take a tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.1769 - acc: 0.9487 - val_loss: 0.0635 - val_acc: 0.9807\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 25s 502us/step - loss: 0.0578 - acc: 0.9821 - val_loss: 0.0483 - val_acc: 0.9861\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 26s 520us/step - loss: 0.0393 - acc: 0.9875 - val_loss: 0.0487 - val_acc: 0.9863\n",
      "Epoch 4/10\n",
      "37632/50000 [=====================>........] - ETA: 6s - loss: 0.0283 - acc: 0.9913"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-71c505b272eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#          Highly customizable under the hood.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.fit(x_train, y_train,\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=(x_val, y_val), epochs=10);\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit(X,y) ships with a neat automatic logging.\n",
    "#          Highly customizable under the hood.\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val), epochs=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.30770227e-14,   9.98961150e-06,   3.87038682e-07,\n",
       "          9.99962568e-01,   9.67699532e-11,   2.42764918e-06,\n",
       "          1.18438042e-13,   2.80407857e-08,   2.39016117e-05,\n",
       "          7.54026246e-07],\n",
       "       [  2.06568629e-07,   9.35589242e-07,   1.40226084e-05,\n",
       "          5.38882450e-04,   1.76302635e-08,   1.90223564e-05,\n",
       "          3.61740575e-08,   1.48443803e-07,   9.99397755e-01,\n",
       "          2.89846685e-05]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate probabilities P(y|x)\n",
    "model.predict_proba(X_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save trained weights\n",
    "model.save(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 22us/step\n",
      "\n",
      "Loss, Accuracy =  [0.13707935359505938, 0.96079999999999999]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoss, Accuracy = \", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoops!\n",
    "So far our model is staggeringly inefficient. There is something wring with it. Guess, what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 96.08 %\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Your network can do better!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-bfb39f8b725d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Logistic regression can do better!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.975\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Your network can do better!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Great job!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your network can do better!"
     ]
    }
   ],
   "source": [
    "# Test score...\n",
    "test_predictions = model.predict_proba(X_test).argmax(axis=-1)\n",
    "test_answers = y_test.argmax(axis=-1)\n",
    "\n",
    "test_accuracy = np.mean(test_predictions==test_answers)\n",
    "\n",
    "print(\"\\nTest accuracy: {} %\".format(test_accuracy*100))\n",
    "\n",
    "assert test_accuracy>=0.92,\"Logistic regression can do better!\"\n",
    "assert test_accuracy>=0.975,\"Your network can do better!\"\n",
    "print(\"Great job!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_submitter = grading.Grader(\"0ybD9ZxxEeea8A6GzH-6CA\")\n",
    "answer_submitter.set_answer(\"N56DR\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_submitter.submit(<your-email>, <your-assignment-token>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras + tensorboard\n",
    "\n",
    "Remember the interactive graphs from Tensorboard one notebook ago? \n",
    "\n",
    "Thing is, Keras can use tensorboard to show you a lot of useful information about the learning progress. Just take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -r /tmp/tboard/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=10,\n",
    "          callbacks=[TensorBoard(\"/tmp/tboard\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips & tricks\n",
    "\n",
    "Here are some tips on what you could do. Don't worry, to reach the passing threshold you don't need to try all the ideas listed here, feel free to stop once you reach the 0.975 accuracy mark.\n",
    "\n",
    " * __Network size__\n",
    "   * More neurons, \n",
    "   * More layers, ([docs](https://keras.io/))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "\n",
    " * __Early Stopping__\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "     \n",
    "\n",
    " * __Faster optimization__\n",
    "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "\n",
    "\n",
    " * __Regularize__ to prevent overfitting\n",
    "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
    "     * Can be done manually or via - https://keras.io/regularizers/\n",
    "   \n",
    "   \n",
    " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
    "   * https://keras.io/preprocessing/image/\n",
    "   * Zoom-in+slice = move\n",
    "   * Rotate+zoom(to remove black stripes)\n",
    "   * any other perturbations\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
